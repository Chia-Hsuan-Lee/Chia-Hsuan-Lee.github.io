---
title: "ODSQA: Open-domain Spoken Question Answering Dataset"
collection: publications
permalink: /publication/2018-12-18-paper-ODSQA
excerpt:
date: 2018-12-18
venue: 'IEEE Spoken Language Technology(SLT)'
paperurl: 
citation:
---
**Chia-Hsuan Lee**, Shang-Ming Wang, Huan-Cheng Chang, Hung-Yi Lee [[PDF]](https://arxiv.org/pdf/1808.02280.pdf) [[Corpus]](https://github.com/chiahsuan156/ODSQA)
<pre style="background-color: rgb(230,230,230);white-space: pre-wrap;">
<font size="1">
@inproceedings{lee2018odsqa,
  title={Odsqa: Open-domain spoken question answering dataset},
  author={Lee, Chia-Hsuan and Wang, Shang-Ming and Chang, Huan-Cheng and Lee, Hung-Yi},
  booktitle={2018 IEEE Spoken Language Technology Workshop (SLT)},
  pages={949--956},
  year={2018},
  organization={IEEE}
}
</font>
</pre>


## Abstract
Reading comprehension by machine has been widely studied, but machine comprehension of spoken content is still a less investigated problem.In this paper, we release Open-Domain Spoken Question Answering Dataset (ODSQA) with more than three thousand questions. To the best of our knowledge, this is the largest real SQA dataset. On this dataset, we found that ASR errors have catastrophic impact on SQA. To mitigate the effect of ASR errors, subword units are involved, which brings consistent improvements over all the models. We further found that data augmentation on text-based QA training examples can improve SQA.
