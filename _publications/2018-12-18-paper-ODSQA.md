---
title: "ODSQA: Open-domain Spoken Question Answering Dataset"
collection: publications
permalink: /publication/2018-12-18-paper-ODSQA
date: 2018-12-18
venue: 'IEEE Spoken Language Technology(SLT) 2018'
paperurl: 
citation:
---
[[PDF]](https://arxiv.org/abs/1808.02280) [[Corpus]](https://github.com/chiahsuan156/ODSQA)

<pre style="background-color: rgb(230,230,230);white-space: pre-wrap;">
<font size="1">
@article{lee2018odsqa,
  title={ODSQA: Open-domain Spoken Question Answering Dataset},
  author={Lee, Chia-Hsuan and Wang, Shang-Ming and Chang, Huan-Cheng and Lee, Hung-Yi},
  journal={arXiv preprint arXiv:1808.02280},
  year={2018}
}
</font>
</pre>

## Abstract
Reading comprehension by machine has been widely studied, but machine comprehension of spoken content is still a less investigated problem.In this paper, we release Open-Domain Spoken Question Answering Dataset (ODSQA) with more than three thousand questions. To the best of our knowledge, this is the largest real SQA dataset. On this dataset, we found that ASR errors have catastrophic impact on SQA. To mitigate the effect of ASR errors, subword units are involved, which brings consistent improvements over all the models. We further found that data augmentation on text-based QA training examples can improve SQA.
